{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gfu8hVAUq18"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community\n",
        "!pip install replicate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import Replicate\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set the API token\n",
        "api_token = userdata.get('api_token')\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = api_token\n",
        "\n",
        "# Model setup\n",
        "model = \"ibm-granite/granite-3.0-8b-instruct\"\n",
        "\n",
        "output = Replicate(\n",
        "    model=model,\n",
        "    replicate_api_token=api_token,\n",
        ")\n",
        "\n",
        "# Define the customer reviews\n",
        "customer_reviews = [\n",
        "    \"The battery lasts all day, but the phone gets hot during gaming.\",\n",
        "    \"The screen is too dim outdoors, but I love the colors indoors.\",\n",
        "    \"This phone is fast, but it keeps crashing when I open certain apps.\"\n",
        "]\n",
        "\n",
        "# Refine the prompt to include reviews\n",
        "reviews_text = \"\\n\".join([f\"Review {i+1}: {review}\" for i, review\n",
        "                          in enumerate(customer_reviews)])\n",
        "\n",
        "# Step 1: Refine Parameters for Initial Prompt\n",
        "# parameters = {\n",
        "#     \"topk\": 0,\n",
        "#     \"top_p\": 1.0,\n",
        "#     \"max_tokens\": 256,\n",
        "#     \"min_tokens\": 0,\n",
        "#     \"random_seed\": None,\n",
        "#     \"repetition_penalty\": 1.0,\n",
        "#     \"stopping_criteria\": \"length (256 tokens)\",\n",
        "#     \"stopping_sequence\": None\n",
        "# }\n",
        "\n",
        "# parameters = {\n",
        "#     \"topk\": 5,\n",
        "#     \"top_p\": 0.85,\n",
        "#     \"max_tokens\": 512,\n",
        "#     \"min_tokens\": 0,\n",
        "#     \"random_seed\": None,\n",
        "#     \"repetition_penalty\": 1.1,\n",
        "#     \"stopping_criteria\": None,\n",
        "#     \"stopping_sequence\": None\n",
        "# }\n",
        "\n",
        "# parameters = {\n",
        "#     \"topk\": 0,\n",
        "#     \"top_p\": 1.0,\n",
        "#     \"max_tokens\": 256,\n",
        "#     \"min_tokens\": 0,\n",
        "#     \"random_seed\": None,\n",
        "#     \"repetition_penalty\": 1.0,\n",
        "#     \"stopping_criteria\": \"length (256 tokens)\",\n",
        "#     \"stopping_sequence\": None\n",
        "# }\n",
        "\n",
        "# controlled_diversity_parameters = {\n",
        "#     \"topk\": 5,\n",
        "#     \"top_p\": 1.0,\n",
        "#     \"max_tokens\": 256,\n",
        "#     \"min_tokens\": 0,\n",
        "#     \"random_seed\": None,\n",
        "#     \"repetition_penalty\": 1.0,\n",
        "#     \"stopping_criteria\": \"length (256 tokens)\",\n",
        "#     \"stopping_sequence\": None\n",
        "# }\n",
        "parameters = {\n",
        "    \"topk\": 1,\n",
        "    \"top_p\": 0.5,\n",
        "    \"max_tokens\": 3,\n",
        "    \"min_tokens\": 1,\n",
        "    \"random_seed\": None,\n",
        "    \"repetition_penalty\": 1.5,\n",
        "    \"stopping_criteria\": \"length\",\n",
        "    \"stopping_sequence\": \" \"\n",
        "}\n",
        "\n",
        "\n",
        "# prompt = f\"\"\"\n",
        "# Classify these reviews as Positive, Negative, or Mixed:\n",
        "\n",
        "# {reviews_text}\n",
        "# \"\"\"\n",
        "\n",
        "# # Invoke the model with the initial prompt\n",
        "# response = output.invoke(prompt, parameters=parameters)\n",
        "\n",
        "# # Print the response\n",
        "# print(\"Granite Model Response:\\n\")\n",
        "\n",
        "# print(response)\n",
        "\n",
        "# Define refined prompt\n",
        "refined_prompt = f\"\"\"\n",
        "Classify these reviews as Positive, Negative, or Mixed, and\n",
        "tag relevant focus areas:\n",
        "\n",
        "{reviews_text}\n",
        "\"\"\"\n",
        "\n",
        "# Invoke the model with the refined prompt\n",
        "response = output.invoke(refined_prompt, parameters=parameters)\n",
        "\n",
        "# Print the response\n",
        "print(\"Granite Model Refined Response:\\n\")\n",
        "\n",
        "print(response)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TUB8_GLkU1CJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}