{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gfu8hVAUq18"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community\n",
        "!pip install replicate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import Replicate\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set the API token\n",
        "api_token = userdata.get('api_token')\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = api_token\n",
        "\n",
        "# Model setup\n",
        "model = \"ibm-granite/granite-3.0-8b-instruct\"\n",
        "\n",
        "output = Replicate(\n",
        "    model=model,\n",
        "    replicate_api_token=api_token,\n",
        ")\n",
        "\n",
        "# Define the customer reviews\n",
        "customer_reviews = [\n",
        "    \"The battery lasts all day, but the phone gets hot during gaming.\",\n",
        "    \"The screen is too dim outdoors, but I love the colors indoors.\",\n",
        "    \"This phone is fast, but it keeps crashing when I open certain apps.\"\n",
        "]\n",
        "\n",
        "# Refine the prompt to include reviews\n",
        "reviews_text = \"\\n\".join([f\"Review {i+1}: {review}\" for i, review\n",
        "                          in enumerate(customer_reviews)])\n",
        "\n",
        "# Set model parameters for prompting with default values\n",
        "# parameters = {\n",
        "#     \"top_k\": 0,\n",
        "#     \"top_p\": 1.0,\n",
        "#     \"max_tokens\": 256,\n",
        "#     \"min_tokens\": 0,\n",
        "#     \"random_seed\": None,\n",
        "#     \"repetition_penalty\": 1.0,\n",
        "#     \"stopping_criteria\": \"length (256 tokens)\",\n",
        "#     \"stopping_sequence\": None\n",
        "# }\n",
        "\n",
        "\n",
        "# parameters = {\n",
        "#     \"top_k\": 5,\n",
        "#     \"top_p\": 0.85,\n",
        "#     \"max_tokens\": 512,\n",
        "#     \"min_tokens\": 0,\n",
        "#     \"random_seed\": None,\n",
        "#     \"repetition_penalty\": 1.1,\n",
        "#     \"stopping_criteria\": None,\n",
        "#     \"stopping_sequence\": None\n",
        "# }\n",
        "\n",
        "# parameters = {\n",
        "#     \"top_k\": 0,\n",
        "#     \"top_p\": 1.0,\n",
        "#     \"max_tokens\": 256,\n",
        "#     \"min_tokens\": 0,\n",
        "#     \"random_seed\": None,\n",
        "#     \"repetition_penalty\": 1.0,\n",
        "#     \"stopping_criteria\": \"length (256 tokens)\",\n",
        "#     \"stopping_sequence\": None\n",
        "# }\n",
        "\n",
        "# parameters = {\n",
        "#     \"top_k\": 5,\n",
        "#     \"top_p\": 1.0,\n",
        "#     \"max_tokens\": 256,\n",
        "#     \"min_tokens\": 0,\n",
        "#     \"random_seed\": None,\n",
        "#     \"repetition_penalty\": 1.0,\n",
        "#     \"stopping_criteria\": \"length (256 tokens)\",\n",
        "#     \"stopping_sequence\": None\n",
        "# }\n",
        "\n",
        "# parameters = {\n",
        "#     \"top_k\": 1,\n",
        "#     \"top_p\": 0.5,\n",
        "#     \"max_tokens\": 10,\n",
        "#     \"min_tokens\": 3,\n",
        "#     \"random_seed\": None,\n",
        "#     \"repetition_penalty\": 1.5,\n",
        "#     \"stopping_criteria\": \"length\",\n",
        "#     \"stopping_sequence\": None\n",
        "# }\n",
        "\n",
        "parameters = {\n",
        "    \"top_k\": 1,\n",
        "    \"top_p\": 0.5,\n",
        "    \"max_tokens\": 3,\n",
        "    \"min_tokens\": 1,\n",
        "    \"random_seed\": None,\n",
        "    \"repetition_penalty\": 1.5,\n",
        "    \"stopping_criteria\": \"length\",\n",
        "    \"stopping_sequence\": \" \"\n",
        "}\n",
        "\n",
        "\n",
        "# Refine multiple Model Parameter values\n",
        "parameters = {\n",
        "    \"top_k\": 1,\n",
        "    \"top_p\": 0.5,\n",
        "    \"max_tokens\": 3,\n",
        "    \"min_tokens\": 1,\n",
        "    \"random_seed\": None,\n",
        "    \"repetition_penalty\": 1.5,\n",
        "    \"stopping_criteria\": \"length\",\n",
        "    \"stopping_sequence\": \" \"\n",
        "}\n",
        "\n",
        "# Define refined prompt\n",
        "refined_prompt = f\"\"\"\n",
        "Classify these reviews as positive, negative, or mixed, and\n",
        "tag relevant focus areas such as battery life, screen quality,\n",
        "or performance\n",
        "\n",
        "{reviews_text}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Invoke the model with the refined prompt\n",
        "response = output.invoke(refined_prompt, parameters=parameters)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Print the response\n",
        "print(\"Granite Model Refined Response:\\n\")\n",
        "\n",
        "print(response)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TUB8_GLkU1CJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c2007f4-3726-42e7-b685-5bee95011103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Granite Model Refined Response:\n",
            "\n",
            "1. Positive: Battery life, Negative: Heat during gaming\n",
            "2. Negative: Screen brightness outdoors, Positive: Screen colors indoors\n",
            "3. Positive: Speed, Negative: App crashing\n"
          ]
        }
      ]
    }
  ]
}